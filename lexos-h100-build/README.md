# LexOS H100 Command Center

![LexOS Logo](static/lexos-logo.png)

A powerful AI command center that maximizes your H100 GPU with open-source models, providing a complete virtual assistant, strategist, manager, and trusted advisor.

## ğŸš€ Features

- **H100-First Architecture**: Optimized for NVIDIA H100 GPU
- **Open-Source Priority**: Uses proven open-source models as primary
- **Cost-Effective**: 90%+ reduction in API costs vs. closed-source alternatives
- **Multi-Agent System**: CrewAI-powered specialized agents
- **Persistent Memory**: Long and short-term memory with document storage
- **Natural Conversation**: Human-like interaction with context awareness
- **Internet Access**: Unlimited and fully open access to the web
- **Shadow Agent**: Unrestricted model access for educational purposes

## ğŸ§  Model Stack

### Local H100 Models
- **Llama 3.1 8B**: Fast local responses
- **CodeLlama 7B**: Quick code tasks
- **Mistral 7B**: Lightweight tasks
- **Stable Diffusion XL**: Image generation
- **Whisper Large v3**: Speech-to-text
- **XTTS v2**: Text-to-speech
- **LLaVA 1.6 34B**: Vision & multimodal

### Together AI Models (Cost-Optimized)
- **Qwen2.5 72B** ($0.60/1M tokens): Main reasoning & strategy
- **DeepSeek R1** ($0.55/1M tokens): Advanced problem solving
- **Llama 3.1 70B** ($0.88/1M tokens): General conversation
- **CodeLlama 34B** ($0.78/1M tokens): Code generation
- **Mixtral 8x22B** ($1.20/1M tokens): Complex reasoning

## ğŸ—ï¸ Architecture

### Core Components
- **Orchestrator**: Intelligent request routing
- **Memory System**: Persistent context and knowledge
- **Agent Framework**: Multi-agent collaboration
- **Tool Integration**: LangChain and n8n workflows

### Intelligent Routing
```
User Request â†’ LexOS Orchestrator â†’ Best Agent/Model
â”œâ”€â”€ Code Tasks â†’ CodeLlama + GitHub Copilot Agent
â”œâ”€â”€ Research â†’ Qwen2.5 + Web Search Agent  
â”œâ”€â”€ Creative â†’ Llama 3.1 + Media Generation Agent
â”œâ”€â”€ Analysis â†’ DeepSeek R1 + Data Agent
â”œâ”€â”€ Personal â†’ Uncensored Llama + Shadow Agent
â””â”€â”€ Management â†’ Mixtral 8x22B + Planning Agent
```

## ğŸ› ï¸ Installation

### Prerequisites
- NVIDIA H100 GPU (80GB VRAM)
- Ubuntu 22.04 or later
- Docker and Docker Compose
- 64GB+ system RAM
- 2TB+ NVMe SSD for models

### Quick Start
```bash
# Clone the repository
git clone https://github.com/yourusername/lexos-h100-command-center.git
cd lexos-h100-command-center

# Configure environment
cp .env.example .env
# Edit .env with your API keys and settings

# Start the system
docker-compose up -d
```

### API Keys (Optional)
For hybrid mode with API fallback:
```
TOGETHER_API_KEY=your_together_api_key
OPENAI_API_KEY=your_openai_api_key  # Optional fallback
```

## ğŸ“š Documentation

### API Endpoints
- `/api/chat`: Text generation and chat
- `/api/image`: Image generation
- `/api/speech-to-text`: Audio transcription
- `/api/text-to-speech`: Speech synthesis
- `/api/crew/*`: Multi-agent management
- `/api/memory/*`: Memory management
- `/ws/chat/{client_id}`: WebSocket for real-time chat

### WebUI
Access the web interface at `http://localhost:80`

## ğŸ”§ Configuration

### Model Configuration
Edit `config/model_config.yaml` to:
- Add/remove models
- Adjust routing preferences
- Configure cost optimization
- Set performance parameters

### Memory Settings
- **Vector Database**: Qdrant (default)
- **Document Storage**: MongoDB
- **Caching**: Redis

## ğŸš€ Development

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Run API server
python -m api.main
```

### Building Docker Image
```bash
docker build -t lexos-h100-command-center .
```

## ğŸ“Š Performance

### Response Times (H100 Local)
- **Simple Chat**: <1 second
- **Complex Reasoning**: 2-5 seconds
- **Code Generation**: 3-8 seconds
- **Image Generation**: 5-15 seconds

### Throughput (Single H100)
- **Concurrent Users**: 10-20 (depending on model)
- **Requests/Hour**: 500-2000
- **Uptime Target**: 99.5%

## ğŸ”’ Security

- **Shadow Agent**: Isolated from main system
- **API Keys**: Securely stored in environment variables
- **Authentication**: JWT-based user authentication
- **HTTPS**: TLS/SSL support for secure communication

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgements

- [CrewAI](https://github.com/joaomdmoura/crewAI)
- [LangChain](https://github.com/langchain-ai/langchain)
- [vLLM](https://github.com/vllm-project/vllm)
- [Together AI](https://www.together.ai/)
- [Qdrant](https://github.com/qdrant/qdrant)

---

Built with â¤ï¸ for maximizing your H100 investment

