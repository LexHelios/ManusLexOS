# LexOS Model Configuration

# Local H100 Models
h100_models:
  # Text generation models
  text:
    - name: llama-3.1-8b
      path: meta-llama/Llama-3.1-8B-Instruct
      type: text
      max_tokens: 4096
      quantization: none  # or int8, int4 for memory optimization
      tensor_parallel: 1  # increase for larger models
      vram_required_gb: 8
      priority: high
      capabilities:
        - chat
        - summarization
        - translation
      
    - name: mistral-7b
      path: mistralai/Mistral-7B-Instruct-v0.2
      type: text
      max_tokens: 8192
      quantization: none
      tensor_parallel: 1
      vram_required_gb: 7
      priority: high
      capabilities:
        - chat
        - summarization
        - translation
  
  # Code generation models
  code:
    - name: codellama-7b
      path: codellama/CodeLlama-7b-Instruct-hf
      type: code
      max_tokens: 4096
      quantization: none
      tensor_parallel: 1
      vram_required_gb: 7
      priority: high
      capabilities:
        - code_generation
        - code_explanation
        - debugging
  
  # Vision models
  vision:
    - name: llava-34b
      path: llava-hf/llava-1.6-34b-hf
      type: vision
      max_tokens: 4096
      quantization: int8
      tensor_parallel: 2
      vram_required_gb: 20
      priority: medium
      capabilities:
        - image_understanding
        - visual_qa
        - scene_description
  
  # Image generation models
  image:
    - name: sdxl
      path: stabilityai/stable-diffusion-xl-base-1.0
      type: image
      vram_required_gb: 12
      priority: medium
      capabilities:
        - image_generation
        - image_editing
  
  # Speech models
  speech:
    - name: whisper-large-v3
      path: openai/whisper-large-v3
      type: speech-to-text
      vram_required_gb: 5
      priority: medium
      capabilities:
        - transcription
        - translation
    
    - name: xtts-v2
      path: coqui/XTTS-v2
      type: text-to-speech
      vram_required_gb: 4
      priority: medium
      capabilities:
        - speech_synthesis
        - voice_cloning

# Together AI Models
together_models:
  - name: qwen2.5-72b
    model_id: Qwen/Qwen2.5-72B-Instruct
    type: text
    max_tokens: 32768
    cost_per_1m_tokens: 0.60
    priority: high
    capabilities:
      - reasoning
      - planning
      - strategy
      - creative_writing
  
  - name: deepseek-r1
    model_id: deepseek-ai/deepseek-r1-llm-chat
    type: text
    max_tokens: 32768
    cost_per_1m_tokens: 0.55
    priority: high
    capabilities:
      - reasoning
      - problem_solving
      - mathematics
  
  - name: llama-3.1-70b
    model_id: meta-llama/Llama-3.1-70B-Instruct
    type: text
    max_tokens: 8192
    cost_per_1m_tokens: 0.88
    priority: medium
    capabilities:
      - creative_writing
      - storytelling
      - roleplay
  
  - name: codellama-34b
    model_id: codellama/CodeLlama-34b-Instruct
    type: code
    max_tokens: 16384
    cost_per_1m_tokens: 0.78
    priority: medium
    capabilities:
      - code_generation
      - code_explanation
      - debugging
      - system_design
  
  - name: mixtral-8x22b
    model_id: mistralai/Mixtral-8x22B-Instruct-v0.1
    type: text
    max_tokens: 32768
    cost_per_1m_tokens: 1.20
    priority: low
    capabilities:
      - complex_reasoning
      - knowledge_intensive
      - long_context

# Shadow Agent Models (Unrestricted)
shadow_models:
  - name: wizard-uncensored
    path: TheBloke/WizardLM-2-8B-Uncensored-GPTQ
    type: text
    max_tokens: 4096
    quantization: int4
    vram_required_gb: 5
    priority: low
    capabilities:
      - unrestricted_content
      - educational_adult_content
      - controversial_topics

# Routing Configuration
routing:
  # Task type to model mapping
  task_mapping:
    chat: 
      - local: mistral-7b
      - together: llama-3.1-70b
    
    reasoning:
      - together: qwen2.5-72b
      - together: deepseek-r1
      - local: llama-3.1-8b
    
    code:
      - local: codellama-7b
      - together: codellama-34b
    
    creative:
      - together: llama-3.1-70b
      - local: llama-3.1-8b
    
    vision:
      - local: llava-34b
    
    image_generation:
      - local: sdxl
    
    speech_to_text:
      - local: whisper-large-v3
    
    text_to_speech:
      - local: xtts-v2
    
    unrestricted:
      - local: wizard-uncensored

  # Cost optimization settings
  cost_optimization:
    prefer_local: true
    max_daily_api_budget: 5.00  # USD
    token_threshold_for_api: 1000  # Use API only for longer contexts
    
  # Performance settings
  performance:
    max_concurrent_local_models: 3
    max_waiting_time_seconds: 5
    preload_models:
      - mistral-7b
      - codellama-7b

